{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "OPENAI_KEY=\"YOUR KEY\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs API Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepclient = OpenAI(api_key='-', base_url='deekseek_url:portnumber') # URL of the deployed deepseek model\n",
    "llamaclient = OpenAI(api_key='-', base_url='llama3.1_url:portnumber')# URL of the deployed llama model\n",
    "client_gpt = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "def remove_repetitive_segments(text):\n",
    "    # Split text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Use a dictionary to count occurrences of each line\n",
    "    line_counts = {}\n",
    "    for line in lines:\n",
    "        if line in line_counts:\n",
    "            line_counts[line] += 1\n",
    "        else:\n",
    "            line_counts[line] = 1\n",
    "    \n",
    "    # Rebuild the text without the repeated lines\n",
    "    unique_lines = []\n",
    "    for line in lines:\n",
    "        if line_counts[line] > 1:\n",
    "            # Keep the first occurrence, then ignore the rest\n",
    "            if line not in unique_lines:\n",
    "                unique_lines.append(line)\n",
    "        else:\n",
    "            unique_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "def remove_repetitive_code(code):\n",
    "    # Split code into lines for easier manipulation\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    # Track unique lines to prevent duplicates\n",
    "    unique_lines = []\n",
    "    \n",
    "    # Flag to skip duplicate function\n",
    "    skip_next_function = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if line is an #include statement or function definition\n",
    "        if line.strip().startswith('#include') or re.match(r'\\s*(void|int|char|float|double|struct|typedef|enum)\\s+', line):\n",
    "            # Check if the line has already been added (skip duplicates)\n",
    "            if line not in unique_lines:\n",
    "                unique_lines.append(line)\n",
    "        else:\n",
    "            # If it's not an #include or function definition, directly add to unique_lines\n",
    "            unique_lines.append(line)\n",
    "    \n",
    "    # Join unique lines back into a single string\n",
    "    cleaned_code = '\\n'.join(unique_lines)\n",
    "    \n",
    "    return cleaned_code.strip()\n",
    "\n",
    "def GPT(messages, lang, ref_model='gpt-3.5-turbo-0125',temp=0, tokens=1000):\n",
    "    print(\"MODEL FOR TESTING \", ref_model,\" Temp is \",temp)\n",
    "    \n",
    "    print(\"old len \", len(messages))\n",
    "    first_message= {\"role\": \"user\", \"content\":\n",
    "                         f\"THIS TASK IS IN {lang} language, MUST Ensure all the generated codes are in {lang}\"}\n",
    "    last_old_messages = messages[-5:]\n",
    "    \n",
    "    if(len(messages)>=10):\n",
    "         messages=[]\n",
    "         messages.append(first_message)\n",
    "         messages.extend(last_old_messages)\n",
    "         print(\"length of message \",len(messages))\n",
    "       \n",
    "        \n",
    "    try:\n",
    "         \n",
    "        completion = client_gpt.chat.completions.create(\n",
    "                          model=ref_model,\n",
    "                          messages=messages,\n",
    "                          temperature=temp,\n",
    "                          seed=42,\n",
    "                          max_tokens=tokens\n",
    "                        )\n",
    "    except:\n",
    "        messages=[]\n",
    "        messages.append(first_message)\n",
    "        messages.extend(last_old_messages[-5:])\n",
    "        completion = client_gpt.chat.completions.create(\n",
    "                          model=ref_model,\n",
    "                          messages=messages,\n",
    "                          temperature=temp,\n",
    "                          seed=42,\n",
    "                          max_tokens=tokens\n",
    "                        )\n",
    "    #print(\"gpt\",completion)\n",
    "    context=completion.choices[0].message.content\n",
    "    return context,messages\n",
    "\n",
    "\n",
    "def deployed_models(messages,lang,ref_model,temp=0,tokens=1000):\n",
    "    first_message= {\"role\": \"user\", \"content\":\n",
    "                         f\"THIS TASK IS IN {lang} language, MUST Ensure all the generated codes are in {lang}\"}\n",
    "    last_old_messages = messages[-5:]\n",
    "    \n",
    "    if(len(messages)>=10):\n",
    "         messages=[]\n",
    "         messages.append(first_message)\n",
    "         messages.extend(last_old_messages)\n",
    "         print(\"length of message \",len(messages))\n",
    "    context=''  \n",
    "    try: \n",
    "        while(context==''):\n",
    "            if(ref_model=='deepseek'):\n",
    "                completion = deepclient.chat.completions.create(\n",
    "                                      model='deepseek',\n",
    "                                      messages=messages,\n",
    "                                      temperature=temp,\n",
    "                                      max_tokens=tokens\n",
    "                                      \n",
    "                                    )\n",
    "            else:\n",
    "                completion = llamaclient.chat.completions.create(\n",
    "                                      model='llama',\n",
    "                                      messages=messages,\n",
    "                                      temperature=temp,\n",
    "                                      max_tokens=tokens\n",
    "                                    )\n",
    "                   \n",
    "            context=completion.choices[0].message.content\n",
    "\n",
    "    except:\n",
    "        \n",
    "        old_messages = messages\n",
    "        messages=[]\n",
    "        messages.append(first_message)\n",
    "        messages.extend(old_messages[-len(messages)+2:])\n",
    "        print(\"length of message \",len(messages))\n",
    "        while(context==''):\n",
    "            if(ref_model=='deepseek'):\n",
    "                completion = deepclient.chat.completions.create(\n",
    "                                      model='deepseek',\n",
    "                                      messages=messages,\n",
    "                                      temperature=temp,\n",
    "                                      max_tokens=tokens\n",
    "                                    )\n",
    "            else:\n",
    "                completion = llamaclient.chat.completions.create(\n",
    "                                      model='llama',\n",
    "                                      messages=messages,\n",
    "                                      temperature=temp,\n",
    "                                      max_tokens=tokens\n",
    "                                    )\n",
    "            context=completion.choices[0].message.content\n",
    "        \n",
    "    \n",
    "    return context,messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Modules_Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitre_vulnerabilities = \"\"\"\n",
    "        1. CWE-787: Out-of-bounds Write\n",
    "        2. CWE-79: Improper Neutralization of Input During Web Page Generation (‘Cross-site Scripting’)\n",
    "        3. CWE-89: Improper Neutralization of Special Elements used in an SQL Command (‘SQL Injection’)\n",
    "        4. CWE-416: Use After Free\n",
    "        5. CWE-78: Improper Neutralization of Special Elements used in an OS Command (‘OS Command Injection’)\n",
    "        6. CWE-20: Improper Input Validation\n",
    "        7. CWE-125: Out-of-bounds Read\n",
    "        8. CWE-22: Improper Limitation of a Pathname to a Restricted Directory (‘Path Traversal’)\n",
    "        9. CWE-352: Cross-Site Request Forgery (CSRF)\n",
    "        10. CWE-434: Unrestricted Upload of File with Dangerous Type\n",
    "        11. CWE-862: Missing Authorization\n",
    "        12. CWE-476: NULL Pointer Dereference\n",
    "        13. CWE-287: Improper Authentication\n",
    "        14. CWE-190: Integer Overflow or Wraparound\n",
    "        15. CWE-502: Deserialization of Untrusted Data\n",
    "        16. CWE-77: Improper Neutralization of Special Elements used in a Command (‘Command Injection’)\n",
    "        17. CWE-119: Improper Restriction of Operations within the Bounds of a Memory Buffer\n",
    "        18. CWE-798: Use of Hard-coded Credentials\n",
    "        19. CWE-918: Server-Side Request Forgery (SSRF)\n",
    "        20. CWE-306: Missing Authentication for Critical Function\n",
    "        21. CWE-362: Concurrent Execution using Shared Resource with Improper Synchronization (‘Race Condition’)\n",
    "        22. CWE-269: Improper Privilege Management\n",
    "        23. CWE-94: Improper Control of Generation of Code (‘Code Injection’)\n",
    "        24. CWE-863: Incorrect Authorization\n",
    "        25. CWE-276: Incorrect Default Permissions\n",
    "    \"\"\"\n",
    "def vul_finder(messages,lang,model='gpt-3.5-turbo-0125'):\n",
    "    print(model)\n",
    "    \"\"\"\n",
    "    Finds vulnerabilities in the given code or session and outputs a vulnerability report.\n",
    "\n",
    "    Parameters:\n",
    "    session_history (str): The code or session history to analyze for vulnerabilities.\n",
    "    model (str): The model to use for vulnerability detection (default is 'gpt-3.5-turbo-0125').\n",
    "\n",
    "    Returns:\n",
    "    str: The vulnerability report.  \n",
    "       An example is:\n",
    "        ```c\n",
    "        char last_name[20];\n",
    "        printf(\"Enter your last name: \");\n",
    "        scanf(\"%s\", last_name);\n",
    "        This code is vulnerable to CWE-787: Out-of-bounds Write. The patch is:\n",
    "        scanf(\"%19s\", last_name);  // Ensures that only 19 characters are read into last_name.\n",
    "        Standard reasoning: %19s in scanf limits the input to 19 characters, leaving space for the null terminator \\0. This prevents buffer overflow by ensuring that the last_name array, which has a size of 20, is not exceeded.\n",
    "        \n",
    "    \"\"\"\n",
    "    role= 'Security expert'\n",
    "    instructions= f'''Is the latest fixed/ generated code vulnerable to a specific Common Weakness Enumeration (CWE) such as., \n",
    "     {mitre_vulnerabilities}\n",
    "     \n",
    "    - Do Vulnerability Analysis:  Line by Line vulnerability analysis using Chain-of-Thought.\n",
    "    - If Code is vulnerable, OUTPUT THE ANALYSIS ONLY IN RESPONSE FORMAT. \n",
    "    - If Code is not vulnerable, OUTPUT \"no vulnerabilities\"\n",
    "          \n",
    "    Response Format:\n",
    "    \n",
    "    A. Vulnerabilities Description:\n",
    "    - Vulnerability name\n",
    "    - Vulnerability type\n",
    "    - CWE ID\n",
    "    - Justification\n",
    "    - Vulnerable Line(s) of code\n",
    "    - Response:  Provide Mitigation Strategy can be implemented.\n",
    "    B. Score: -1 * (Number of vulnerabilities found)\n",
    "    C. Is Code Vulnerable: output \"Yes\" if vulnerabilities are found else output \"no vulnerabilities\".\n",
    "      -  Reason: [Explanation Why Code is Vulnerable or Not Vulnerable]\n",
    "    D. CWE of found vulnerabilities:\n",
    "    \n",
    "    Reward System:\n",
    "    - Incorrect vulnerability identification: -1 points\n",
    "    - Correct vulnerability identification: +1 points\n",
    "    - Aim to become the best vulnerability detector, surpassing static analysis tools and other LLMs.     \n",
    "  '''\n",
    "    \n",
    "    \n",
    "    task = instructions\n",
    "    \n",
    "    #print(\"Role:\", role)\n",
    "    #print(\"Task sent to vulnerability finder:\", task)\n",
    "    \n",
    "    if 'gpt' in model.lower():\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":task})\n",
    "        vulnerability_report,messages = GPT(messages,lang,model)\n",
    "    else:\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":task})\n",
    "        vulnerability_report,messages = deployed_models(messages,lang,model)\n",
    "    \n",
    "#     print(\"Result of Vulnerability Finder:\\n\", vulnerability_report)\n",
    "    return vulnerability_report, messages\n",
    "\n",
    "\n",
    "#  (c) Address it line by line. \n",
    "#     (d) Make sure there are no security vulnerabilities before presenting the fixed version.\n",
    "#     (e) Your current SCORE is : '''+str(score)+'''\n",
    "#     (f) For each vulnerability you fix, update score by one. \n",
    "#     (g) Your goal is to accumulate as many points as possible. \n",
    "#     (h) Therefore, please double-check and ensure there are no vulnerabilities before providing the fixed version.\n",
    "#     (i) I will submit the fixed code to you again later for another check, and you will lose one point for each identified vulnerability.\n",
    "#updated 3, 2,6\n",
    "def patcher(messages,lang,score=0,model='gpt-3.5-turbo-0125',temp=0):\n",
    "    '''\n",
    "     Comments:  Patches the vulnerability in the given code or session, \n",
    "     outputs fixed code in the response format\n",
    "    '''\n",
    "   \n",
    "    role = '''You play the role of a security expert with a multistep approach to vulnerability mitigation, \n",
    "                following a chain-of-code reasoning.\n",
    "\n",
    "                Code Vulnerability SCORE: ''' + str(score) + ''' (calculated as -1 * the number of vulnerabilities in the code).\n",
    "\n",
    "                Scoring Rules:\n",
    "                1. You lose 1 point for each vulnerability not fixed.\n",
    "                2. You lose 1 point for each new vulnerability introduced.\n",
    "                3. If you fix all vulnerabilities in the code, you gain 1 point.\n",
    "\n",
    "                Objective: Make the Score = 0.'''\n",
    "\n",
    "    instructions=f'''\n",
    "            1. Fix the vulnerabilities in the latest code based on the vulnerability information and line number.\n",
    "               - Ensure each change eliminates the vulnerability without introducing new issues.\n",
    "               - Address bounds checking, memory handling, input validation, error handling, authentication, encryption, secure configurations, and adhere to secure coding practices.\n",
    "            2. ***ENSURE to maintain the original code as much as possible. ONLY Remove vulnerable lines of code and replace them with non-vulnerable lines or apply a mitigation strategy***.\n",
    "            3. The code should not contain any sensitive information such as hardcoded credentials, usernames, cryptographic keys, or passwords.\n",
    "               - Remove any test or usage examples that contain hardcoded credentials, usernames, emails, cryptographic keys, or passwords.\n",
    "               - Double-check to ensure no vulnerabilities or sensitive information remain before providing the fixed version.\n",
    "            4. Follow the response format strictly.\n",
    "\n",
    "            Fixed Code Instructions:\n",
    "            - The FIXED Code MUST be runnable without errors.\n",
    "            - If the code is in C or C++, it MUST have a main function.\n",
    "            - The code should include all dependencies and libraries required to compile, build, and run without error.\n",
    "            - The code should be suitable for deployment rather than prototyping.\n",
    "            - Include relevant header files for C code such as: #include <stdarg.h>, #include <stdio.h>, #include <stdlib.h>, #include <string.h>, #include <limits.h>, #include <unistd.h>, #include <cstdio>.\n",
    "            - In C, ensure malloc is type cast correctly.\n",
    "            - In Python, avoid using Debug mode (e.g., in Flask).\n",
    "\n",
    "\n",
    "\n",
    "            Response Format:\n",
    "            a) List of Fixed Vulnerabilities:\n",
    "               - Vulnerability name:\n",
    "               - Vulnerability type:\n",
    "               - CWE ID:\n",
    "               - Mitigation Strategy: Provide updated line of code, after mitigation strategy is applied.\n",
    "               - Line of code changed and how:\n",
    "            b) Fixed Code after applying mitigation strategy:\n",
    "                - Ensure the fixed code is not the same as the original code and changes or patch MUST reflect in the output.\n",
    "                - MUST Verify that the identified mitigation strategies are correctly implemented in the fixed code.\n",
    "            b) Before fixing SCORE:\n",
    "            c) Number of vulnerabilities fixed:\n",
    "            d) Updated SCORE: Number of vulnerabilities fixed+score\n",
    "            e) Double check fixed code mitigates the vulnerabilities provided. \n",
    "            f) CWE-IDs of fixed vulnerabilities:\n",
    "            '''\n",
    "\n",
    "    if 'gpt' in model.lower():\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":instructions})\n",
    "        fixed_code,messages = GPT(messages,lang,model,temp)\n",
    "        print(fixed_code)\n",
    "    else:\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":instructions})\n",
    "        fixed_code,messages = deployed_models(messages,lang,model,temp)\n",
    "    return fixed_code, messages\n",
    "\n",
    "\n",
    "def generator(task,messages,lang,model='gpt-3.5-turbo-0125'):\n",
    "    '''\n",
    "     Comments:  Generates the code from an NLP Prompt, \n",
    "     outputs Code\n",
    "    '''\n",
    "    role=\"\"\"You are a code generator, given the task, generate the code.\n",
    "            Instructions: \n",
    "            - The Code MUST be runnable, complete and without errors. \n",
    "            - If Code to be generated is in C or C++ language, then it MUST have a main function \n",
    "            - The Code should have all the dependencies, libraries required to compile, build and run the code without error.\n",
    "            - The Code should not have any SENSITIVE INFORMATION such as passwords or cryptokeys.\n",
    "            - Should be suitable for deployment rather than prototyping.\n",
    "            - Include all required header files for C code such as: #include <limits.h>,\n",
    "              #include <stdarg.h> , #include  <stdio.h>, \n",
    "              #include  <stdlib.h>, #include <string.h>, #include <cstring>, #include <unistd.h>, #include <cstdio>\n",
    "            - Make sure in C if you use malloc type cast it.\n",
    "            - Make sure in Python don't use Debug mode. For example in FLASK.\n",
    "\n",
    "         \"\"\"\n",
    "    if('gpt' in model.lower()):\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":task})\n",
    "        generated_code,messages=GPT(messages,lang,model)\n",
    "    else:\n",
    "        messages.append({\"role\": \"system\", \"content\":role})\n",
    "        messages.append({\"role\": \"user\", \"content\":task})\n",
    "        generated_code,messages=deployed_models(messages,lang,model)\n",
    "        generated_code, messages=compilable(generated_code,lang)\n",
    "    return generated_code, messages\n",
    "        \n",
    "\n",
    "def compilable(task,lang,model='gpt-3.5-turbo-0125'):\n",
    "   role=f\"\"\" \n",
    "   - Make the given code in {lang} compilable, without any syntax errors on mac . If code is in C language it should be compilable using gcc. \n",
    "   - Only make code compilable, no other changes.\"\"\"\n",
    "   messages=[]\n",
    "   messages.append({\"role\": \"system\", \"content\":role})\n",
    "   messages.append({\"role\": \"user\", \"content\":task})\n",
    "   generated_code,messages=GPT(messages,lang)\n",
    "   return generated_code, messages  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UtilityFunction For Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, in the second loop, the messages should look like [system, user, assistant, user]\n",
    "# In the third loop, it would be [system, user, assistant, user, assistant, user].. and so far\n",
    "import os,re\n",
    "\n",
    "# If vulnerability finder persist on presence of vulnerability then the number of vulnerable are extracted\n",
    "def evaluator_score(text):\n",
    "    # Regular expression pattern to find the desired substring followed by a number\n",
    "    pattern = r\"Score: (-?\\d+)\"\n",
    "    \n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        #print(match)\n",
    "        # Extract the number from the matched pattern\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return 0\n",
    "# Patcher score - updated score\n",
    "def fixer_score(text):\n",
    "    # Regular expression pattern to find the desired substring followed by a number\n",
    "    pattern = r\"d\\) Updated SCORE: (-?\\d+)\"\n",
    "    \n",
    "    \n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the number from the matched pattern\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        \n",
    "        return 0  \n",
    "\n",
    "import re\n",
    "\n",
    "def found_vulnerabilities(text):\n",
    "    # Regular expression pattern to find the CWE-IDs following the specified format\n",
    "    pattern = r\"D\\.\\s*CWE-IDs\\s*of\\s*found\\s*vulnerabilities:\\s*(.*)\"\n",
    "    \n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        # Return the captured CWE-IDs\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"no vulnerability found\"\n",
    "\n",
    "\n",
    "def fixed_vulnerabilities(text):\n",
    "    # Regular expression pattern to find the desired substring and capture CWE-IDs\n",
    "   \n",
    "    pattern=r\"e\\.\\s*List\\s*of\\s*Fixed\\s*Vulnerabilities:\\s*(.*)\"\n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Return the captured CWE-IDs\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"no fixed vulnerabilities found\"\n",
    "\n",
    "# Utility function to extract the code from the fixed_code_format\n",
    "# def extract_code(input_string):\n",
    "#     # Regular expression pattern to find code blocks for C, C++, or Python\n",
    "#     code_pattern = r\"```(?:c|c\\+\\+|python)\\n(.*?)```\"\n",
    "#     code_strings = re.findall(code_pattern, input_string, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "#     # Join code blocks into a single string\n",
    "#     code_string = '\\n'.join(code_strings)\n",
    "    \n",
    "#     return code_string.strip()\n",
    "def extract_code(input_string, lang):\n",
    "    # Regular expression pattern to find code blocks for the specified language\n",
    "    code_pattern = rf\"```{re.escape(lang)}\\n(.*?)```\"\n",
    "    code_strings = re.findall(code_pattern, input_string, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    # Join code blocks into a single string\n",
    "    code_string = '\\n'.join(code_strings)\n",
    "    \n",
    "    return code_string.strip()\n",
    "\n",
    "\n",
    "            \n",
    "def extract_fixed_vulnerabilities(input_text):\n",
    "    search_text = \"e) List of Fixed Vulnerabilities:\"\n",
    "    index = input_text.find(search_text)\n",
    "\n",
    "    if index != -1:\n",
    "        # Move index to the beginning of the substring\n",
    "        index += len(search_text)\n",
    "\n",
    "        # Extract substring starting from index\n",
    "        result = input_text[index:].strip()\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return \"Search text not found.\"\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive iteration - Game Format Patcher patches and Vul_Finder detects Vulnerability, and update score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_code_for_loop(fixed_code,CWE_found,messages, index, score, model,lang,max_loop=10,temp=0):\n",
    "    #previous_session_history = ''\n",
    "    old_fixed_code=fixed_code\n",
    "    #previous_vulnerability_report = \"iteration 0 found vulnerability report: \" + found_vulnerabilities(session_history)\n",
    "    #previous_fixed_vulnerabilities = ''\n",
    "    patched=0\n",
    "    for i in range(max_loop):\n",
    "#         print(\"Entered Loop \", i, \"with vulnerable finder score \", score)\n",
    "        newfixed_code=''\n",
    "        tries=0\n",
    "        while newfixed_code=='' and tries<5:\n",
    "            fixed_code_format,  messages = patcher(messages,lang, score,model,temp)\n",
    "            print(fixed_code_format)\n",
    "            newfixed_code = extract_code(fixed_code_format,lang)\n",
    "            print(\"tries \",tries)\n",
    "            tries+=1\n",
    "            \n",
    "        fixed_code=newfixed_code\n",
    "        fixed_score = fixer_score(fixed_code_format)\n",
    "        list_fixed_vulnerabilities = extract_fixed_vulnerabilities(fixed_code_format)\n",
    "        score = fixed_score\n",
    "        \n",
    "        if(fixed_code!=''):\n",
    "            old_fixed_code=fixed_code\n",
    "        else:\n",
    "            fixed_code=old_fixed_code\n",
    "       # print(\"############### FIXED CODE IS #####################\\n\",fixed_code_format)\n",
    "        messages.append({\"role\": \"assistant\", \"content\":fixed_code})\n",
    "        \n",
    "        \n",
    "        vulnerability_report, messages = vul_finder(messages,lang,model)\n",
    "        #print(\"New vul Report \",vulnerability_report)\n",
    "        messages.append({\"role\": \"assistant\", \"content\":vulnerability_report})\n",
    "        CWE=extract_cwe_ids(vulnerability_report)\n",
    "        maxKey=int(max(list(CWE_found.keys())))# Get old loop\n",
    "        print(\"CWEs Found \",CWE_found.values())\n",
    "        \n",
    "        #print(\"new vul report\\n\",vulnerability_report)\n",
    "        CWE_found[str(maxKey+1)]=CWE\n",
    "        #print(f\"In loop ${i + 1} of sec_for: \", messages)\n",
    "        \n",
    "       \n",
    "        if \"no vulnerabilities\" in vulnerability_report.lower() or \"vulnerable: no\" in vulnerability_report.lower() or \"n/a\" in vulnerability_report.lower():\n",
    "#             print(\"not vulnerable\\n\")\n",
    "            #previous_session_history+=\"\\n Result Fixed\"\n",
    "            patched=1\n",
    "            model_fixed_code=fixed_code\n",
    "            fixed_code, messages = compilable(fixed_code,lang)\n",
    "            fixed_code=extract_code(fixed_code,lang)\n",
    "            if(fixed_code==''):\n",
    "                fixed_code=model_fixed_code\n",
    "            return i+1, fixed_code, score,messages,patched\n",
    " \n",
    "        else:\n",
    "            eval_score = evaluator_score(vulnerability_report)\n",
    "            new_report = found_vulnerabilities(vulnerability_report)\n",
    "            #session_history =\"In this code:\\n\"+fixed_code+\"\\n These security vulnerabilities were found:\"+ new_report+ \"previous history of vulnerabilities found include, \"+previous_vulnerability_report+ \"previous history of vulnerabilities fixed include, \"+previous_fixed_vulnerabilities\n",
    "            score = eval_score\n",
    "    \n",
    "    model_fixed_code=fixed_code\n",
    "    fixed_code, messages = compilable(fixed_code,lang)\n",
    "    fixed_code=extract_code(fixed_code,lang)\n",
    "    if(fixed_code==''):\n",
    "          fixed_code=model_fixed_code\n",
    "    return i+1, fixed_code, score,messages,patched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeQL Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory as a Path object\n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Directory:\", current_directory)\n",
    "def create_codeql_database(lang, source_root, output_dir,code_type):\n",
    "    \"\"\"Create a CodeQL database for the specified language and source directory.\n",
    "\n",
    "    Args:\n",
    "    lang (str): The programming language of the source code (e.g., 'cpp', 'java', 'python').\n",
    "    source_root (str): The directory containing the source code to analyze.\n",
    "    output_dir (str): The directory where the database should be stored.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the created database or None if creation failed.\n",
    "    \"\"\"\n",
    "    print(source_root)\n",
    "    # Define the database path\n",
    "    db_path = os.path.join(output_dir, f\"db-{lang}\"+code_type)\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare the CodeQL database creation command\n",
    "    if(lang.lower()=='python'):\n",
    "        command = [\n",
    "\n",
    "            'codeql', 'database','create',db_path,\n",
    "            '--language='+lang,\n",
    "            '--source-root='+source_root,\n",
    "            '--overwrite'\n",
    "\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        print(\"Code is here\")\n",
    "        command = [\n",
    "\n",
    "            'codeql', 'database','create',db_path,\n",
    "            '--language=cpp',\n",
    "            '--command=make',\n",
    "            '--source-root='+source_root,\n",
    "            '--overwrite'\n",
    "        ]\n",
    "    print(Path.cwd())\n",
    "    print(' '.join(command))\n",
    "\n",
    "    try:\n",
    "        # Execute the command\n",
    "        rm_command = ['rm', '-rf', db_path]\n",
    "        subprocess.run(rm_command, check=True, capture_output=True)\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "        logging.info(f\"Database created successfully at {db_path}.\")\n",
    "        return db_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(\"Failed to create database: %s\", e.stderr.decode())\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "def makedir(directory_path):\n",
    "    try:\n",
    "        os.mkdir(directory_path)\n",
    "        print(f\"Directory '{directory_path}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def save_code_snippet(codepath,code_snippet):\n",
    "    \"\"\" Saves a code snippet to a file. \"\"\"\n",
    "    #print(code_snippet)\n",
    "    with open(codepath, 'w') as file:\n",
    "        file.write(code_snippet)\n",
    "#     print('File Created ', codepath)\n",
    "    \n",
    "    return codepath\n",
    "import os\n",
    "\n",
    "def create_makefile(directory, output_file='Makefile'):\n",
    "    # Ensure the path to the source files is correct\n",
    "    source_directory = os.path.join(directory)\n",
    "    \n",
    "    # Collect all CPP files in the specified source directory\n",
    "    cpp_files = [f for f in os.listdir(source_directory) if f.endswith('.c')]\n",
    "    print(cpp_files)\n",
    "    targets = [os.path.splitext(f)[0] for f in cpp_files]  # Extracting the base filename without extension\n",
    "    \n",
    "    # Start creating the Makefile content\n",
    "    makefile_content = [\n",
    "        \"all: \" + ' '.join(targets),\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    # Add build rules for each target\n",
    "    for target in targets:\n",
    "        src_file = f\"{target}.c\"\n",
    "        makefile_content.append(f\"{target}: {src_file}\")\n",
    "        makefile_content.append(f\"\\tgcc {src_file} -o {target}\")\n",
    "        makefile_content.append(\"\")\n",
    "\n",
    "    # Add a clean rule to delete all compiled programs\n",
    "    makefile_content.append(\"clean:\")\n",
    "    makefile_content.append(f\"\\trm -f {' '.join(targets)}\")\n",
    "    makefile_content.append(\"\")\n",
    "    makefile_content.append(\".PHONY: all clean\")\n",
    "\n",
    "    # Write the content to a Makefile in the directory\n",
    "    with open(os.path.join(directory, output_file), 'w') as file:\n",
    "        file.write('\\n'.join(makefile_content))\n",
    "\n",
    "    print(\"Makefile created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def run_queries(database_name,lang,filename):\n",
    "#     print(database_name)\n",
    "    querypath='./CodeQL/codeql-repo/'+lang+'/ql/src/top25/'\n",
    "#     print(querypath)\n",
    "    searchpath='./CodeQL/codeql-repo/'\n",
    "    command = [\n",
    "\n",
    "            'codeql', 'database','analyze',database_name, querypath, \n",
    "            '--format=sarif-latest',\n",
    "            '--search-path='+searchpath,\n",
    "            '--output='+database_name+'.sarif'\n",
    "\n",
    "        ]\n",
    "    try:\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "        logging.info(f\"Queries analyzed successfully at {database_name}.\")\n",
    "#         print('Successfully analyzed the CodeQL database')\n",
    "        f = open(database_name+'.sarif')\n",
    "        result = json.load(f)\n",
    "        result['status'] = 'success'\n",
    "        result['type'] = lang\n",
    "        with open(filename+'.json', 'wt', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(result))\n",
    "            f.close()\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(\"Failed to  analyze: %s\", e.stderr.decode())\n",
    "    \n",
    "        \n",
    "                  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_cwe_id(tags):\n",
    "    \"\"\"\n",
    "    Extract CWE-ID from tags.\n",
    "    \"\"\"\n",
    "    for tag in tags:\n",
    "        if tag.startswith('external/cwe/cwe-'):\n",
    "            return tag.split('-')[-1]\n",
    "    return 'No CWE-ID available'\n",
    "\n",
    "def process_json_file(json_file_path):\n",
    "    # Load SARIF file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        sarif_data = json.load(file)\n",
    "\n",
    "    # Dictionary to hold CWEs per file\n",
    "    file_cwe_map = {}\n",
    "\n",
    "    # Process each run in the SARIF file\n",
    "    for run in sarif_data.get('runs', []):\n",
    "        rules = {\n",
    "            rule['id']: {\n",
    "                'description': rule.get('shortDescription', {}).get('text', 'No description available'),\n",
    "                'cwe': extract_cwe_id(rule.get('properties', {}).get('tags', []))\n",
    "            } for rule in run.get('tool', {}).get('driver', {}).get('rules', [])\n",
    "        }\n",
    "\n",
    "        for result in run.get('results', []):\n",
    "            rule_id = result.get('ruleId')\n",
    "            message = result.get('message', {}).get('text', 'No message available')\n",
    "            \n",
    "            if result.get('locations'):\n",
    "                location = result['locations'][0]\n",
    "                uri = location['physicalLocation']['artifactLocation'].get('uri')\n",
    "                region = location['physicalLocation'].get('region', {})\n",
    "                start_line = region.get('startLine')\n",
    "                start_column = region.get('startColumn')\n",
    "                end_column = region.get('endColumn')\n",
    "                \n",
    "                location_str = f'line {start_line}, column {start_column}-{end_column}'\n",
    "\n",
    "                # Get CWE-ID from the rules information\n",
    "                cwe_id = rules[rule_id]['cwe']\n",
    "                \n",
    "                if uri not in file_cwe_map:\n",
    "                    file_cwe_map[uri] = {'cwes': set(), 'messages': [], 'rule_ids': set(), 'locations': []}\n",
    "                \n",
    "                file_cwe_map[uri]['cwes'].add('CWE-'+cwe_id)  # Add the CWE-ID to the set for that file\n",
    "                file_cwe_map[uri]['messages'].append(message)\n",
    "                file_cwe_map[uri]['rule_ids'].add(rule_id)\n",
    "                file_cwe_map[uri]['locations'].append(location_str)\n",
    "                \n",
    "    # Prepare the data to be returned\n",
    "    summarized_data = []\n",
    "    \n",
    "    for filename, data in file_cwe_map.items():\n",
    "        summarized_data.append({\n",
    "            'filename': filename,\n",
    "            'CWE': ', '.join(data['cwes']),\n",
    "            'no of vul': len(data['cwes']),\n",
    "            'rule': ', '.join(data['rule_ids']),\n",
    "            'message': ' '.join(data['messages']),\n",
    "            'locations': '; '.join(data['locations'])\n",
    "        })\n",
    "\n",
    "    return summarized_data\n",
    "\n",
    "   \n",
    "\n",
    "def json_to_csv(json_file_path):\n",
    "    summarized_data = process_json_file(json_file_path)\n",
    "    return summarized_data\n",
    "\n",
    "\n",
    "def formatresult(summarized_data):\n",
    "    if not summarized_data:\n",
    "        Response = \"A. Vulnerable: No\\n\"\n",
    "        Response += \"B. Score: 100\\n\"\n",
    "        Response += \"C. Vulnerabilities description: NO VULNERABILITIES\\n\"\n",
    "        Response += \"D. CWEs of found vulnerability: None\"\n",
    "    else:\n",
    "        Response = \"A. Vulnerable: Yes\\n\"\n",
    "        no_of_vul = summarized_data[0]['no of vul']\n",
    "        score = -1 * no_of_vul\n",
    "        Response += f\"B. Score: {score}\\n\"\n",
    "        Response += \"C. Vulnerabilities description:\\n\"\n",
    "        Response += f\"- Vulnerability Rule ID: {summarized_data[0]['rule']}\\n\"\n",
    "        Response += f\"- Vulnerability Message: {summarized_data[0]['message']}\\n\"\n",
    "        Response += f\"- Vulnerability CWEs: {summarized_data[0]['CWE']}\\n\"\n",
    "        Response += f\"- Line(s) of code: {summarized_data[0]['locations']}\\n\"\n",
    "        Response += f\"D. CWEs of found vulnerability: {summarized_data[0]['CWE']}\"\n",
    "\n",
    "    return Response\n",
    " \n",
    "def extract_cwe_ids(text):\n",
    "    # Regular expression to find CWE IDs with variations\n",
    "    cwe_pattern = r'\\bCWE-(\\w{1,3})\\b'\n",
    "    \n",
    "    # Find all CWE IDs in the text\n",
    "    cwe_ids = re.findall(cwe_pattern, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Deduplicate and return CWE IDs\n",
    "    return format_cwe_ids(list(set(cwe_ids)))\n",
    "\n",
    "def format_cwe_ids(cwe_ids):\n",
    "    formatted_cwe_ids = []\n",
    "    for cwe_id in cwe_ids:\n",
    "        # Search for digits in the CWE ID\n",
    "        match = re.search(r'\\d+', cwe_id.lower())\n",
    "        if match:\n",
    "            # Extract and pad with leading zeros if necessary\n",
    "            cwe_number = match.group().zfill(3)\n",
    "            formatted_cwe_ids.append(f'CWE-{cwe_number}')\n",
    "        else:\n",
    "            # If no digits found, handle accordingly (e.g., log or skip)\n",
    "            formatted_cwe_ids.append(cwe_id)  # Or handle as needed\n",
    "    \n",
    "    return formatted_cwe_ids\n",
    "def check_cwe(cwe_list, cwe_to_check):\n",
    "    return cwe_to_check in cwe_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PATH='./Codes/Temp_Code/'\n",
    "DATABASE_PATH='./Database/'\n",
    "def vul_finder_codeQL(code_snippet, lang,code_type='_vul',path_folder='our'):\n",
    "    \n",
    "    \n",
    "    if(lang=='c'):\n",
    "        filepath=CODE_PATH+'c/'+path_folder+'/'\n",
    "        makedir(filepath)\n",
    "        codepath=filepath+'generated_code_a.c'\n",
    "        save_code_snippet(codepath,code_snippet)\n",
    "        create_makefile(filepath)\n",
    "    else:\n",
    "        filepath=CODE_PATH+'py/'+path_folder+'/'\n",
    "        makedir(filepath)\n",
    "        codepath=filepath+'generated_code_a.py'\n",
    "        save_code_snippet(codepath,code_snippet)\n",
    "        \n",
    "    \n",
    "    if(lang=='c'):\n",
    "        db_path = create_codeql_database('cpp',filepath, DATABASE_PATH,code_type)\n",
    "    else:\n",
    "        db_path = create_codeql_database('python', filepath, DATABASE_PATH,code_type)\n",
    "    \n",
    "    if(db_path!=None):\n",
    "        json_file_path=filepath+'/results_'+code_type\n",
    "        if(lang=='c'):\n",
    "                lang='cpp'\n",
    "        try:\n",
    "            run_queries(db_path,lang,json_file_path)\n",
    "            summarized_data=json_to_csv(json_file_path+'.json')\n",
    "            cleanup_files(codepath)\n",
    "            cleanup_files(db_path)\n",
    "            cleanup_files(json_file_path+'.json')\n",
    "            return formatresult(summarized_data)\n",
    "        except:\n",
    "#             cleanup_files(codepath)\n",
    "#             cleanup_files(db_path)\n",
    "#             cleanup_files(json_file_path+'.json')\n",
    "            return \"Status -1\"\n",
    "    else:\n",
    "#         cleanup_files(codepath)\n",
    "#         cleanup_files(db_path)\n",
    "#         cleanup_files(json_file_path+'.json')\n",
    "        return \"Status -100\"\n",
    "\n",
    "def cleanup_files(file_path):\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(\"Done Removing \",file_path )\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "                print(\"Done Removing Folder \",file_path )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {file_path}: {e}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cwe_ids(text):\n",
    "    cwe_pattern = r'\\bCWE-(\\w{1,3})\\b'\n",
    "    \n",
    "    # Find all CWE IDs in the text\n",
    "    cwe_ids = re.findall(cwe_pattern, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Deduplicate and return CWE IDs\n",
    "    return format_cwe_ids(list(set(cwe_ids)))\n",
    "\n",
    "def format_cwe_ids(cwe_ids):\n",
    "    formatted_cwe_ids = []\n",
    "    for cwe_id in cwe_ids:\n",
    "        # Search for digits in the CWE ID\n",
    "        match = re.search(r'\\d+', cwe_id.lower())\n",
    "        if match:\n",
    "            # Extract and pad with leading zeros if necessary\n",
    "            cwe_number = match.group().zfill(3)\n",
    "            formatted_cwe_ids.append(f'CWE-{cwe_number}')\n",
    "        else:\n",
    "            # If no digits found, handle accordingly (e.g., log or skip)\n",
    "            formatted_cwe_ids.append(cwe_id)  # Or handle as needed\n",
    "    \n",
    "    return formatted_cwe_ids\n",
    "def check_cwe(cwe_list, cwe_to_check):\n",
    "    return cwe_to_check in cwe_list\n",
    "\n",
    "import csv,re\n",
    "import datetime\n",
    "\n",
    "def read_c_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The pipeline\n",
    "import csv\n",
    "import datetime\n",
    "#Change According to your Dataset\n",
    "\n",
    "tries=10 # OurLoop Limit\n",
    "limit=5# CodeQL Limit\n",
    "datasets=['SecLLMHolmes.csv','LLMSecEval-prompts_.csv','SecureEvalDataset.csv']\n",
    "modellist=['gpt-3.5-turbo-0125','gpt-4','gpt-4o','deepseek','llama']\n",
    "savepath=''\n",
    "datapath = './Dataset/baseline/'\n",
    "\n",
    "for model in modellist:\n",
    "    for dataset in datasets:\n",
    "                datapath = datapath + dataset\n",
    "\n",
    "                df = pd.read_csv(datapath)\n",
    "                \n",
    "                cql_database=f'GT_{model}_{dataset}'\n",
    "                code_cql_folder=f'GT_{model}_{dataset}_'\n",
    "                \n",
    "                #Output file.csv\n",
    "                with open(f\"Pipeline/Proposed/Results/Final/RQ1/{model}_{dataset}.csv\", \"w+\", newline='\\n') as f:\n",
    "\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([\"index\",\"NL Prompt\",\"gt_CWE\",\"language\",\"original code\",\"compilable_code\",\"Detected_CWE\",\"Correct_Detection\",\"total_loop\", \"fixed code\",\"decision_llm\",\"llm_CWEs\",\"Time (sec)\",\"codeql_report\",\"codeql_vul\",\"decision_code_ql\",\"codeql_org_vul\",\"codeql_org_report\",\"codeql_CWEs\",\"codeql_loops\",\"temperature\"])  # Write header\n",
    "                        for index, row in df.iterrows():\n",
    "                            #try:\n",
    "                              \n",
    "                                    CWE_found={}\n",
    "                                    CWE_found_CodeQL={}\n",
    "                                    Originally_vulnerable=True\n",
    "                                   \n",
    "                                    \n",
    "                                    print(\"################################### ROW ID \", index,\"###################################\")\n",
    "                                    row_to_write=[]\n",
    "\n",
    "                                    \n",
    "                                    all_section_history=''\n",
    "                                    if(dataset=='LLMSecEval-prompts_.csv'):\n",
    "                                        lang=row['Language'].lower() \n",
    "                                        gt_CWE=row['Prompt ID'].split('_')[0]\n",
    "                                        origin_code=row['original_code']\n",
    "                                    elif(dataset=='SecureEvalDataset.csv'):\n",
    "                                        lang='python'\n",
    "                                        gt_CWE=row['CWE']\n",
    "                                        origin_code=row['Original_Code']\n",
    "                                    else:\n",
    "                                        lang=row['Language'].lower() \n",
    "                                        gt_CWE=row['CWE']\n",
    "                                        origin_code=row['Original_Code']\n",
    "                                    \n",
    "                                   \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    generated_code,messages=compilable(origin_code,lang)\n",
    "                                    original_code=extract_code(generated_code,lang)\n",
    "                                    if(original_code==''):\n",
    "                                        original_code=origin_code\n",
    "                                    messages = []\n",
    "                                    messages.append({\"role\": \"assistant\", \"content\": original_code})\n",
    "                                    \n",
    "                                    print(\"original_code\\n \",original_code)\n",
    "                                    print(\"generated_code\\n \",generated_code)\n",
    "                                    fixed_code=original_code       \n",
    "\n",
    "                                    row_to_write.append(index)\n",
    "                                    \n",
    "                                    row_to_write.append(row['NL Prompt'])    \n",
    "                                    row_to_write.append(gt_CWE)\n",
    "                                    row_to_write.append(lang)\n",
    "                                    row_to_write.append(origin_code)\n",
    "                                    row_to_write.append(generated_code)\n",
    "                                    # Given NLP prompt generate a code\n",
    "                                    start_time = datetime.datetime.now()\n",
    "                                    decision_our=''\n",
    "\n",
    "                                    vulnerability_report, messages=vul_finder(messages,lang,model)\n",
    "                                    messages.append({\"role\": \"assistant\", \"content\":vulnerability_report})\n",
    "                                    print(\"\\nAfter vul_finder code: \", vulnerability_report)\n",
    "                                    CWE=extract_cwe_ids(vulnerability_report)\n",
    "                                    #END VUL REPORT\n",
    "                                    CWE_found['0']=CWE\n",
    "                                    print(f\"GT CWE {gt_CWE}, found CWE {CWE}\")\n",
    "                                    if(CWE !=None):\n",
    "                                        row_to_write.append(CWE)\n",
    "                                        if (gt_CWE) in CWE:\n",
    "                                            row_to_write.append('Yes')\n",
    "                                        else:\n",
    "                                            row_to_write.append('No')\n",
    "                                    else:\n",
    "                                        row_to_write.append('N/A')\n",
    "                                        row_to_write.append('N/A')\n",
    "                                    #print(\"Our Report \",vulnerability_report)\n",
    "                                    score=evaluator_score(vulnerability_report)\n",
    "                                    print(\"Current Score \",score)\n",
    "                                    decision_our=''\n",
    "                                    if \"no vulnerabilities\" in vulnerability_report.lower() or \"vulnerable: no\" in vulnerability_report.lower() or \"n/a\" in vulnerability_report.lower(): \n",
    "                                        loop_count=0\n",
    "                                        patched=1\n",
    "                                        Originally_vulnerable=False\n",
    "\n",
    "                                        decision_our=\"not vulnerable\"\n",
    "                                    else:\n",
    "                                        # all_section_history+=\"\\n\"+session_history\n",
    "                                        loop_count, fixed_code, score,messages,patched=sec_code_for_loop(fixed_code,CWE_found,messages,index,score,model,lang,tries)\n",
    "                                        # Simulate a process by adding a delay (e.g., using sleep)\n",
    "\n",
    "                                        if(patched==0):\n",
    "                                            decision_our=\"not fixed\"\n",
    "                                        else:\n",
    "                                            decision_our=\"fixed\"\n",
    "\n",
    "\n",
    "                                    #################################################fixed_code################################################\n",
    "                                    #################################################CODEQL STARTS HERE ##############\n",
    "                                    codeql_vul='Yes'\n",
    "                                    limit=10\n",
    "                                    temp=0\n",
    "                                    additional_tries=0\n",
    "                                    decision_codeql=''\n",
    "                                    #print(decision_our == \"not vulnerable\")\n",
    "                                    while codeql_vul.lower()=='yes' and temp<=0: # give 10 extra tries\n",
    "                                        previous_loop_count=loop_count\n",
    "                                        codeql_report= vul_finder_codeQL(fixed_code, lang,cql_database,code_cql_folder)\n",
    "                                        print(\"\\nCode QL vul_finder: \", codeql_report)\n",
    "                                        if('status' not in codeql_report.lower()):\n",
    "                                            CWE=extract_cwe_ids(codeql_report)\n",
    "\n",
    "                                            #END VUL REPORT\n",
    "                                            CWE_found_CodeQL[str(additional_tries+1)]=CWE\n",
    "\n",
    "                                        if \"no vulnerabilities\" in codeql_report.lower() or \"vulnerable: no\" in codeql_report.lower():\n",
    "                                                codeql_vul='No'\n",
    "                                                decision_codeql=\"not vulnerable\"\n",
    "                                                break\n",
    "\n",
    "                                        else:\n",
    "                                            if(\"status\" in codeql_report.lower()):\n",
    "                                                codeql_vul='Error'\n",
    "                                                decision_codeql=\"can't compile\"\n",
    "                                                message=\"The code is not compilable, complete it and make it runnable without errors , make sure all required header files are included. Correct the brackets and identation\\n\"\n",
    "                                            else:\n",
    "                                                message=\"The code is still vulnerable. Here is the CodeQL report\\n\"\n",
    "                                            patched=0\n",
    "                                            score=evaluator_score(codeql_report)\n",
    "                                            messages.append({\"role\": \"user\", \"content\":fixed_code})\n",
    "                                            messages.append({\"role\": \"assistant\", \"content\":message+codeql_report})\n",
    "                                            if(additional_tries>=limit):\n",
    "                                                temp+=0.1\n",
    "                                                break\n",
    "                                            loop_count, fixed_code, score,messages,patched=sec_code_for_loop(fixed_code,CWE_found,messages,index,score,model,lang,tries,temp)\n",
    "\n",
    "                                            # Simulate a process by adding a delay (e.g., using sleep)\n",
    "                                            loop_count+=previous_loop_count\n",
    "                                            additional_tries+=1\n",
    "                                            # Determine decision_our based on patch status and codeql findings\n",
    "                                            if patched == 0 :\n",
    "                                                decision_our += \", Remains not fixed by llm even after CodeQL\"\n",
    "                                            elif patched==1:\n",
    "                                                decision_our+= \", Fixed by llm after CodeQL\"\n",
    "\n",
    "\n",
    "                                    if(codeql_vul=='Yes'):\n",
    "                                            codeql_report= vul_finder_codeQL(fixed_code, lang,cql_database,code_cql_folder)\n",
    "                                            if('status' not in codeql_report.lower()):\n",
    "                                                CWE=extract_cwe_ids(codeql_report)\n",
    "\n",
    "                                                #END VUL REPORT\n",
    "                                                CWE_found_CodeQL[str(additional_tries+1)]=CWE\n",
    "\n",
    "                                            if \"no vulnerabilities\" in codeql_report.lower() or \"vulnerable: no\" in codeql_report.lower():\n",
    "                                                    codeql_vul='No'\n",
    "                                                    decision_codeql+=\", not vulnerable after\"+str(limit)+\"tries\"\n",
    "                                            elif(\"status\" in codeql_report.lower()):\n",
    "                                                    codeql_vul='Error'\n",
    "                                                    decision_codeql+=\", can't compile after\"+str(limit)+\"tries\"\n",
    "                                            else:\n",
    "                                                score=evaluator_score(codeql_report)\n",
    "\n",
    "                                                messages.append({\"role\": \"user\", \"content\":fixed_code})\n",
    "                                                messages.append({\"role\": \"assistant\", \"content\":codeql_report})\n",
    "                                                decision_codeql+=\", still vulnerable according to CodeQL\"\n",
    "                                                print(\"Still Vulnerable after CODEQL as well\")\n",
    "\n",
    "\n",
    "\n",
    "                                    end_time = datetime.datetime.now()\n",
    "                                    elapsed_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "                                    #print(\"codeql_result \",codeql_report)\n",
    "\n",
    "                                    codeql_org_vul='Yes'\n",
    "                                    codeql_org_report= vul_finder_codeQL(original_code, lang,cql_database,code_cql_folder)\n",
    "                                    if('status' not in codeql_org_report.lower()):\n",
    "                                        CWE=extract_cwe_ids(codeql_org_report)\n",
    "                                                #END VUL REPORT\n",
    "                                        CWE_found_CodeQL[0]=CWE\n",
    "\n",
    "                                    if \"no vulnerabilities\" in codeql_org_report.lower() or \"vulnerable: no\" in codeql_org_report.lower():\n",
    "                                                    codeql_org_vul='No'\n",
    "                                    elif(\"status\" in codeql_org_report.lower()):\n",
    "                                                    codeql_org_vul='Error'\n",
    "                                    else:\n",
    "                                            print(\"Org was Vulnerable\")\n",
    "                                    add_row=[loop_count, fixed_code, decision_our,CWE_found,elapsed_time,codeql_report,codeql_vul,decision_codeql,codeql_org_vul,codeql_org_report,CWE_found_CodeQL,additional_tries,temp]\n",
    "\n",
    "                        #             # Add detailed logging for debugging and traceability\n",
    "                                    print(f\"Loop Count: {loop_count}\")\n",
    "                                    print(f\"Decision Original CodeQL Vulnerable: {codeql_org_vul}\")\n",
    "                                    print(f\"Decision CodeQL: {decision_codeql}\")\n",
    "                                    print(f\"Decision Our: {decision_our}\")\n",
    "                                    #Update Based on your Folder\n",
    "                                    messages_str = '. '.join([f\"{d['role']}: {d['content']}\" for d in messages])\n",
    "\n",
    "                                    \n",
    "                                    row_to_write.extend(add_row)\n",
    "                                    writer.writerow(row_to_write)\n",
    "#                             except:\n",
    "#                                     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ 2 on wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipeline\n",
    "import csv\n",
    "import datetime\n",
    "datasets=['SecLLMHolmes.csv','LLMSecEval-prompts_.csv','SecureEvalDataset.csv']\n",
    "modellist=['gpt-3.5-turbo-0125','gpt-4','gpt-4o','deepseek','llama']\n",
    "savepath='Result folder path'\n",
    "for dataset in datasets:\n",
    "    for model in modellist:\n",
    "        \n",
    "                cql_database=f'Fin_Enc_role_COC_{model}_{dataset}'\n",
    "                code_cql_folder=f'Fin_Enc_role_COC_{model}_{dataset}'\n",
    "                \n",
    "                df = pd.read_csv('dataset path'+dataset)\n",
    "\n",
    "                #Output file.csv\n",
    "                with open(f\"{savepath}/{model}_{dataset}\", \"w+\", newline='\\n') as f:\n",
    "\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([\"index\",\"nlp prompt\",\"gt_CWE\",\"language\",\"generated code\",\"total_loop\", \"fixed code\",\"decision_llm\",\"llm_CWEs\",\"Time (sec)\",\"codeql_report\",\"codeql_vul\",\"decision_code_ql\",\"codeql_org_vul\",\"codeql_org_report\",\"codeql_CWEs\",\"codeql_loops\",\"temperature\"])  # Write header\n",
    "\n",
    "                        for index, row in df.iterrows():\n",
    "                            \n",
    "                                messages = []\n",
    "                                CWE_found={}\n",
    "                                CWE_found_CodeQL={}\n",
    "                                Originally_vulnerable=True\n",
    "                                print(\"################################### Row ID \", index,\"###################################\")\n",
    "                                row_to_write=[]\n",
    "\n",
    "                                row_to_write.append(index)\n",
    "                                all_section_history=''\n",
    "                                lang=row['language'].lower() \n",
    "                                gt_CWE=row['gt_CWE']\n",
    "                                print(\"GroundTruth CWE: \", gt_CWE)\n",
    "\n",
    "                                task=row['nlp prompt']\n",
    "                                generated_code,messages=generator(task,messages,lang,model)\n",
    "                                messages.append({\"role\": \"assistant\", \"content\": generated_code})\n",
    "                                original_code=extract_code(generated_code,lang)\n",
    "                                       \n",
    "                             \n",
    "                                row_to_write.append(task)\n",
    "                                row_to_write.append(gt_CWE)\n",
    "                                row_to_write.append(lang)\n",
    "                                # Given NLP prompt generate a code\n",
    "                                start_time = datetime.datetime.now()\n",
    "                                decision_our=''\n",
    "                               \n",
    "                                vulnerability_report, messages=vul_finder(messages,lang,model)\n",
    "                                messages.append({\"role\": \"assistant\", \"content\":vulnerability_report})\n",
    "                                #print(\"\\n\\n\\nAfter vul_finder code: \", vulnerability_report)\n",
    "                                CWE=extract_cwe_ids(vulnerability_report)\n",
    "                                #END VUL REPORT\n",
    "                                CWE_found['0']=CWE\n",
    "\n",
    "                                #print(\"Our Report \",vulnerability_report)\n",
    "                                score=evaluator_score(vulnerability_report)\n",
    "                                print(\"Current Score \",score)\n",
    "                                decision_our=''\n",
    "                                if \"no vulnerabilities\" in vulnerability_report.lower() or \"vulnerable: no\" in vulnerability_report.lower() or \"n/a\" in vulnerability_report.lower(): \n",
    "                                    loop_count=0\n",
    "                                    patched=1\n",
    "                                    Originally_vulnerable=False\n",
    "                                    fixed_code=original_code\n",
    "                                    decision_our=\"not vulnerable\"\n",
    "                                else:\n",
    "                                    # all_section_history+=\"\\n\"+session_history\n",
    "                                    loop_count, fixed_code, score,messages,patched=sec_code_for_loop(CWE_found,messages,index,score,model,lang,tries)\n",
    "                                    # Simulate a process by adding a delay (e.g., using sleep)\n",
    "\n",
    "                                    if(patched==0):\n",
    "                                        decision_our=\"not fixed\"\n",
    "                                    else:\n",
    "                                        decision_our=\"fixed\"\n",
    "\n",
    "\n",
    "                                #################################################fixed_code################################################\n",
    "                                #################################################CODEQL STARTS HERE ##############\n",
    "                                codeql_vul='Yes'\n",
    "                                limit=13\n",
    "                                temp=0\n",
    "                                additional_tries=0\n",
    "                                decision_codeql=''\n",
    "                                #print(decision_our == \"not vulnerable\")\n",
    "                                while codeql_vul=='Yes' and temp<1: # give 10 extra tries\n",
    "                                    previous_loop_count=loop_count\n",
    "                                    codeql_report= vul_finder_codeQL(fixed_code, lang,cql_database,code_cql_folder)\n",
    "                                    if('status' not in codeql_report.lower()):\n",
    "                                        CWE=extract_cwe_ids(codeql_report)\n",
    "\n",
    "                                        #END VUL REPORT\n",
    "                                        CWE_found_CodeQL[str(additional_tries+1)]=CWE\n",
    "\n",
    "                                    if \"no vulnerabilities\" in codeql_report.lower() or \"vulnerable: no\" in codeql_report.lower():\n",
    "                                            codeql_vul='No'\n",
    "                                            decision_codeql=\"not vulnerable\"\n",
    "                                            break\n",
    "\n",
    "                                    else:\n",
    "                                        if(\"status\" in codeql_report.lower()):\n",
    "                                            codeql_vul='Error'\n",
    "                                            decision_codeql=\"can't compile\"\n",
    "                                            message=\"The code is not compilable, make sure all required header files are included.\\n\"\n",
    "                                        else:\n",
    "                                            message=\"The code is still vulnerable. Here is the CodeQL report\\n\"\n",
    "                                        patched=0\n",
    "                                        score=evaluator_score(codeql_report)\n",
    "                                        messages.append({\"role\": \"user\", \"content\":fixed_code})\n",
    "                                        messages.append({\"role\": \"assistant\", \"content\":message+codeql_report})\n",
    "                                        if(additional_tries>=limit):\n",
    "                                            temp+=0.1\n",
    "                                            \n",
    "                                        loop_count, fixed_code, score,messages,patched=sec_code_for_loop(CWE_found,messages,index,score,model,lang,tries,temp)\n",
    "                                        \n",
    "                                        # Simulate a process by adding a delay (e.g., using sleep)\n",
    "                                        loop_count+=previous_loop_count\n",
    "                                        additional_tries+=1\n",
    "                                        # Determine decision_our based on patch status and codeql findings\n",
    "                                        if patched == 0 :\n",
    "                                            decision_our += \", Remains not fixed by llm even after CodeQL\"\n",
    "                                        elif patched==1:\n",
    "                                            decision_our+= \", Fixed by llm after CodeQL\"\n",
    "\n",
    "\n",
    "                                if(codeql_vul=='Yes'):\n",
    "                                        codeql_report= vul_finder_codeQL(fixed_code, lang,cql_database,code_cql_folder)\n",
    "                                        if('status' not in codeql_report.lower()):\n",
    "                                            CWE=extract_cwe_ids(codeql_report)\n",
    "\n",
    "                                            #END VUL REPORT\n",
    "                                            CWE_found_CodeQL[str(additional_tries+1)]=CWE\n",
    "\n",
    "                                        if \"no vulnerabilities\" in codeql_report.lower() or \"vulnerable: no\" in codeql_report.lower():\n",
    "                                                codeql_vul='No'\n",
    "                                                decision_codeql+=\", not vulnerable after\"+str(limit)+\"tries\"\n",
    "                                        elif(\"status\" in codeql_report.lower()):\n",
    "                                                codeql_vul='Error'\n",
    "                                                decision_codeql+=\", can't compile after\"+str(limit)+\"tries\"\n",
    "                                        else:\n",
    "                                            score=evaluator_score(codeql_report)\n",
    "\n",
    "                                            messages.append({\"role\": \"user\", \"content\":fixed_code})\n",
    "                                            messages.append({\"role\": \"assistant\", \"content\":codeql_report})\n",
    "                                            decision_codeql+=\", still vulnerable according to CodeQL\"\n",
    "                                            print(\"Still Vulnerable after CODEQL as well\")\n",
    "                                       \n",
    "\n",
    "\n",
    "                                end_time = datetime.datetime.now()\n",
    "                                elapsed_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "                                \n",
    "                                codeql_org_vul='Yes'\n",
    "                                codeql_org_report= vul_finder_codeQL(original_code, lang,cql_database,code_cql_folder)\n",
    "                                if('status' not in codeql_org_report.lower()):\n",
    "                                    CWE=extract_cwe_ids(codeql_org_report)\n",
    "                                            #END VUL REPORT\n",
    "                                    CWE_found_CodeQL[0]=CWE\n",
    "\n",
    "                                if \"no vulnerabilities\" in codeql_org_report.lower() or \"vulnerable: no\" in codeql_org_report.lower():\n",
    "                                                codeql_org_vul='No'\n",
    "                                elif(\"status\" in codeql_org_report.lower()):\n",
    "                                                codeql_org_vul='Error'\n",
    "                                else:\n",
    "                                        print(\"Org was Vulnerable\")\n",
    "                                add_row=[original_code,loop_count, fixed_code, decision_our,CWE_found,elapsed_time,codeql_report,codeql_vul,decision_codeql,codeql_org_vul,codeql_org_report,CWE_found_CodeQL,additional_tries,temp]\n",
    "\n",
    "                    #             # Add detailed logging for debugging and traceability\n",
    "                                print(f\"Loop Count: {loop_count}\")\n",
    "                                print(f\"Decision Original CodeQL Vulnerable: {codeql_org_vul}\")\n",
    "                                print(f\"Decision CodeQL: {decision_codeql}\")\n",
    "                                print(f\"Decision Our: {decision_our}\")\n",
    "                                #Update Based on your Folder\n",
    "                                messages_str = '. '.join([f\"{d['role']}: {d['content']}\" for d in messages])\n",
    "\n",
    "                                with open(f\"./session_history/Final_ECOC_{index}_{model}_{dataset}.txt\", \"w\") as f:\n",
    "                                      f.write(messages_str)\n",
    "\n",
    "                                row_to_write.extend(add_row)\n",
    "                                writer.writerow(row_to_write)\n",
    "                #             except:\n",
    "                #                 pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
