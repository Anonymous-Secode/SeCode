{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica;
\f3\fswiss\fcharset0 Helvetica-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red109\green109\blue109;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c50196\c50196\c50196;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa321\partightenfactor0

\f0\b\fs48 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 NL Prompt Dataset for Vulnerable Code Evaluation\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 This repository provides a natural language (NL) prompt dataset designed to evaluate the security of code generated by large language models (LLMs) when given high-level tasks from novice developers. The dataset focuses on assessing how LLMs handle vulnerabilities in generated code, based on real-world examples from three state-of-the-art (SOTA) vulnerable code datasets.\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 Dataset Contents\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Each dataset in this repository includes the following components:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Natural Language Prompts (NL Prompts)
\f1\b0 \uc0\u8232 A translation of the original vulnerable code into a high-level natural language task description. These prompts reflect the type of requests a novice developer might give to an LLM.\
\ls1\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CWE Identifiers (Ground Truth)
\f1\b0 \uc0\u8232 Each entry in the dataset is annotated with the corresponding CWE (Common Weakness Enumeration) ID, providing the ground truth for the type of vulnerability present in the original code.\
\ls1\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Original Vulnerable Code
\f1\b0 \uc0\u8232 The actual code containing vulnerabilities, as found in the original datasets. This serves as the basis for both the natural language prompts and the associated CWE annotations.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 This dataset is ideal for researchers and developers looking to test LLMs' ability to generate secure code in response to ambiguous or imprecise natural language task descriptions.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \

\f3\b Original Code Datasets: 
\f2\b0 \
1) LLMSecEval: {\field{\*\fldinst{HYPERLINK "https://github.com/moyix/AsleepKeyboardDataset/tree/main/data/original"}}{\fldrslt https://github.com/moyix/AsleepKeyboardDataset/tree/main/data/original}} (C and python)\
2) SecureEval: {\field{\*\fldinst{HYPERLINK "https://github.com/s2e-lab/SecurityEval"}}{\fldrslt https://github.com/s2e-lab/SecurityEval}} (python)\
3) SecHolmes: {\field{\*\fldinst{HYPERLINK "https://github.com/ai4cloudops/SecLLMHolmes/tree/main/datasets"}}{\fldrslt https://github.com/ai4cloudops/SecLLMHolmes/tree/main/datasets}} (C and python)}